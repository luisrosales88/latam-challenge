{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este archivo puedes escribir lo que estimes conveniente. Te recomendamos detallar tu solución y todas las suposiciones que estás considerando. Aquí puedes ejecutar las funciones que definiste en los otros archivos de la carpeta src, medir el tiempo, memoria, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para la solución se utilizaron los siguientes servicios cloud:\n",
    "#### 1. Google Cloud Storage, creando un bucket que almacene el archivo de tweets.\n",
    "#### 2. Vertex AI, donde se creó una instancia nueva de Vertex AI Workbench.\n",
    "#### 3. GitHub."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instalaremos todas la librerias que se necesitarán desde el archivo requeriments.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: memory-profiler==0.61.0 in /opt/conda/lib/python3.10/site-packages (from -r ../requirements.txt (line 1)) (0.61.0)\n",
      "Requirement already satisfied: pandas==2.2.1 in /opt/conda/lib/python3.10/site-packages (from -r ../requirements.txt (line 2)) (2.2.1)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from memory-profiler==0.61.0->-r ../requirements.txt (line 1)) (5.9.3)\n",
      "Requirement already satisfied: numpy<2,>=1.22.4 in /opt/conda/lib/python3.10/site-packages (from pandas==2.2.1->-r ../requirements.txt (line 2)) (1.25.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas==2.2.1->-r ../requirements.txt (line 2)) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas==2.2.1->-r ../requirements.txt (line 2)) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas==2.2.1->-r ../requirements.txt (line 2)) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas==2.2.1->-r ../requirements.txt (line 2)) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install -r ../requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bajo el supuesto, que el archivo json tenemos almacenado en un bucket en Google Cloud Storage. Definimos los siguientes datos:<br>\n",
    "Bucket ==> **gs://challenge-de**<br>\n",
    "JSON ==> **farmers-protest-tweets-2021-2-4.json**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Se define la variable **file_path** que almacenará la ruta del archivo de tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "file_path = \"gs://challenge-de/farmers-protest-tweets-2021-2-4.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explorando la data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>date</th>\n",
       "      <th>content</th>\n",
       "      <th>renderedContent</th>\n",
       "      <th>id</th>\n",
       "      <th>user</th>\n",
       "      <th>outlinks</th>\n",
       "      <th>tcooutlinks</th>\n",
       "      <th>replyCount</th>\n",
       "      <th>retweetCount</th>\n",
       "      <th>...</th>\n",
       "      <th>quoteCount</th>\n",
       "      <th>conversationId</th>\n",
       "      <th>lang</th>\n",
       "      <th>source</th>\n",
       "      <th>sourceUrl</th>\n",
       "      <th>sourceLabel</th>\n",
       "      <th>media</th>\n",
       "      <th>retweetedTweet</th>\n",
       "      <th>quotedTweet</th>\n",
       "      <th>mentionedUsers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://twitter.com/ArjunSinghPanam/status/136...</td>\n",
       "      <td>2021-02-24 09:23:35+00:00</td>\n",
       "      <td>The world progresses while the Indian police a...</td>\n",
       "      <td>The world progresses while the Indian police a...</td>\n",
       "      <td>1364506249291784198</td>\n",
       "      <td>{'username': 'ArjunSinghPanam', 'displayname':...</td>\n",
       "      <td>[https://twitter.com/ravisinghka/status/136415...</td>\n",
       "      <td>[https://t.co/es3kn0IQAF]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1364506249291784198</td>\n",
       "      <td>en</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>http://twitter.com/download/iphone</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'url': 'https://twitter.com/RaviSinghKA/statu...</td>\n",
       "      <td>[{'username': 'narendramodi', 'displayname': '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://twitter.com/PrdeepNain/status/13645062...</td>\n",
       "      <td>2021-02-24 09:23:32+00:00</td>\n",
       "      <td>#FarmersProtest \\n#ModiIgnoringFarmersDeaths \\...</td>\n",
       "      <td>#FarmersProtest \\n#ModiIgnoringFarmersDeaths \\...</td>\n",
       "      <td>1364506237451313155</td>\n",
       "      <td>{'username': 'PrdeepNain', 'displayname': 'Pra...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1364506237451313155</td>\n",
       "      <td>en</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/android\" ...</td>\n",
       "      <td>http://twitter.com/download/android</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>[{'thumbnailUrl': 'https://pbs.twimg.com/ext_t...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>[{'username': 'Kisanektamorcha', 'displayname'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://twitter.com/parmarmaninder/status/1364...</td>\n",
       "      <td>2021-02-24 09:23:22+00:00</td>\n",
       "      <td>ਪੈਟਰੋਲ ਦੀਆਂ ਕੀਮਤਾਂ ਨੂੰ ਮੱਦੇਨਜ਼ਰ ਰੱਖਦੇ ਹੋਏ \\nਮੇ...</td>\n",
       "      <td>ਪੈਟਰੋਲ ਦੀਆਂ ਕੀਮਤਾਂ ਨੂੰ ਮੱਦੇਨਜ਼ਰ ਰੱਖਦੇ ਹੋਏ \\nਮੇ...</td>\n",
       "      <td>1364506195453767680</td>\n",
       "      <td>{'username': 'parmarmaninder', 'displayname': ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1364506195453767680</td>\n",
       "      <td>pa</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/android\" ...</td>\n",
       "      <td>http://twitter.com/download/android</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://twitter.com/anmoldhaliwal/status/13645...</td>\n",
       "      <td>2021-02-24 09:23:16+00:00</td>\n",
       "      <td>@ReallySwara @rohini_sgh watch full video here...</td>\n",
       "      <td>@ReallySwara @rohini_sgh watch full video here...</td>\n",
       "      <td>1364506167226032128</td>\n",
       "      <td>{'username': 'anmoldhaliwal', 'displayname': '...</td>\n",
       "      <td>[https://youtu.be/-bUKumwq-J8]</td>\n",
       "      <td>[https://t.co/wBPNdJdB0n]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1364350947099484160</td>\n",
       "      <td>en</td>\n",
       "      <td>&lt;a href=\"https://mobile.twitter.com\" rel=\"nofo...</td>\n",
       "      <td>https://mobile.twitter.com</td>\n",
       "      <td>Twitter Web App</td>\n",
       "      <td>[{'thumbnailUrl': 'https://pbs.twimg.com/ext_t...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>[{'username': 'ReallySwara', 'displayname': 'S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://twitter.com/KotiaPreet/status/13645061...</td>\n",
       "      <td>2021-02-24 09:23:10+00:00</td>\n",
       "      <td>#KisanEktaMorcha #FarmersProtest #NoFarmersNoF...</td>\n",
       "      <td>#KisanEktaMorcha #FarmersProtest #NoFarmersNoF...</td>\n",
       "      <td>1364506144002088963</td>\n",
       "      <td>{'username': 'KotiaPreet', 'displayname': 'Pre...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1364506144002088963</td>\n",
       "      <td>und</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>http://twitter.com/download/iphone</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>[{'previewUrl': 'https://pbs.twimg.com/media/E...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url  \\\n",
       "0  https://twitter.com/ArjunSinghPanam/status/136...   \n",
       "1  https://twitter.com/PrdeepNain/status/13645062...   \n",
       "2  https://twitter.com/parmarmaninder/status/1364...   \n",
       "3  https://twitter.com/anmoldhaliwal/status/13645...   \n",
       "4  https://twitter.com/KotiaPreet/status/13645061...   \n",
       "\n",
       "                       date  \\\n",
       "0 2021-02-24 09:23:35+00:00   \n",
       "1 2021-02-24 09:23:32+00:00   \n",
       "2 2021-02-24 09:23:22+00:00   \n",
       "3 2021-02-24 09:23:16+00:00   \n",
       "4 2021-02-24 09:23:10+00:00   \n",
       "\n",
       "                                             content  \\\n",
       "0  The world progresses while the Indian police a...   \n",
       "1  #FarmersProtest \\n#ModiIgnoringFarmersDeaths \\...   \n",
       "2  ਪੈਟਰੋਲ ਦੀਆਂ ਕੀਮਤਾਂ ਨੂੰ ਮੱਦੇਨਜ਼ਰ ਰੱਖਦੇ ਹੋਏ \\nਮੇ...   \n",
       "3  @ReallySwara @rohini_sgh watch full video here...   \n",
       "4  #KisanEktaMorcha #FarmersProtest #NoFarmersNoF...   \n",
       "\n",
       "                                     renderedContent                   id  \\\n",
       "0  The world progresses while the Indian police a...  1364506249291784198   \n",
       "1  #FarmersProtest \\n#ModiIgnoringFarmersDeaths \\...  1364506237451313155   \n",
       "2  ਪੈਟਰੋਲ ਦੀਆਂ ਕੀਮਤਾਂ ਨੂੰ ਮੱਦੇਨਜ਼ਰ ਰੱਖਦੇ ਹੋਏ \\nਮੇ...  1364506195453767680   \n",
       "3  @ReallySwara @rohini_sgh watch full video here...  1364506167226032128   \n",
       "4  #KisanEktaMorcha #FarmersProtest #NoFarmersNoF...  1364506144002088963   \n",
       "\n",
       "                                                user  \\\n",
       "0  {'username': 'ArjunSinghPanam', 'displayname':...   \n",
       "1  {'username': 'PrdeepNain', 'displayname': 'Pra...   \n",
       "2  {'username': 'parmarmaninder', 'displayname': ...   \n",
       "3  {'username': 'anmoldhaliwal', 'displayname': '...   \n",
       "4  {'username': 'KotiaPreet', 'displayname': 'Pre...   \n",
       "\n",
       "                                            outlinks  \\\n",
       "0  [https://twitter.com/ravisinghka/status/136415...   \n",
       "1                                                 []   \n",
       "2                                                 []   \n",
       "3                     [https://youtu.be/-bUKumwq-J8]   \n",
       "4                                                 []   \n",
       "\n",
       "                 tcooutlinks  replyCount  retweetCount  ...  quoteCount  \\\n",
       "0  [https://t.co/es3kn0IQAF]           0             0  ...           0   \n",
       "1                         []           0             0  ...           0   \n",
       "2                         []           0             0  ...           0   \n",
       "3  [https://t.co/wBPNdJdB0n]           0             0  ...           0   \n",
       "4                         []           0             0  ...           0   \n",
       "\n",
       "        conversationId  lang  \\\n",
       "0  1364506249291784198    en   \n",
       "1  1364506237451313155    en   \n",
       "2  1364506195453767680    pa   \n",
       "3  1364350947099484160    en   \n",
       "4  1364506144002088963   und   \n",
       "\n",
       "                                              source  \\\n",
       "0  <a href=\"http://twitter.com/download/iphone\" r...   \n",
       "1  <a href=\"http://twitter.com/download/android\" ...   \n",
       "2  <a href=\"http://twitter.com/download/android\" ...   \n",
       "3  <a href=\"https://mobile.twitter.com\" rel=\"nofo...   \n",
       "4  <a href=\"http://twitter.com/download/iphone\" r...   \n",
       "\n",
       "                             sourceUrl          sourceLabel  \\\n",
       "0   http://twitter.com/download/iphone   Twitter for iPhone   \n",
       "1  http://twitter.com/download/android  Twitter for Android   \n",
       "2  http://twitter.com/download/android  Twitter for Android   \n",
       "3           https://mobile.twitter.com      Twitter Web App   \n",
       "4   http://twitter.com/download/iphone   Twitter for iPhone   \n",
       "\n",
       "                                               media retweetedTweet  \\\n",
       "0                                               None            NaN   \n",
       "1  [{'thumbnailUrl': 'https://pbs.twimg.com/ext_t...            NaN   \n",
       "2                                               None            NaN   \n",
       "3  [{'thumbnailUrl': 'https://pbs.twimg.com/ext_t...            NaN   \n",
       "4  [{'previewUrl': 'https://pbs.twimg.com/media/E...            NaN   \n",
       "\n",
       "                                         quotedTweet  \\\n",
       "0  {'url': 'https://twitter.com/RaviSinghKA/statu...   \n",
       "1                                               None   \n",
       "2                                               None   \n",
       "3                                               None   \n",
       "4                                               None   \n",
       "\n",
       "                                      mentionedUsers  \n",
       "0  [{'username': 'narendramodi', 'displayname': '...  \n",
       "1  [{'username': 'Kisanektamorcha', 'displayname'...  \n",
       "2                                               None  \n",
       "3  [{'username': 'ReallySwara', 'displayname': 'S...  \n",
       "4                                               None  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Leer el archivo JSON línea por línea\n",
    "df = pd.read_json(file_path, lines=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>replyCount</th>\n",
       "      <th>retweetCount</th>\n",
       "      <th>likeCount</th>\n",
       "      <th>quoteCount</th>\n",
       "      <th>conversationId</th>\n",
       "      <th>retweetedTweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.174070e+05</td>\n",
       "      <td>117407.000000</td>\n",
       "      <td>117407.000000</td>\n",
       "      <td>117407.000000</td>\n",
       "      <td>117407.000000</td>\n",
       "      <td>1.174070e+05</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.362062e+18</td>\n",
       "      <td>0.631410</td>\n",
       "      <td>5.045619</td>\n",
       "      <td>14.609674</td>\n",
       "      <td>0.336241</td>\n",
       "      <td>1.361764e+18</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.293803e+15</td>\n",
       "      <td>9.436159</td>\n",
       "      <td>58.237370</td>\n",
       "      <td>229.083983</td>\n",
       "      <td>4.474576</td>\n",
       "      <td>1.294352e+16</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.360040e+18</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.981606e+10</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.360935e+18</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.360887e+18</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.361945e+18</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.361914e+18</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.363097e+18</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.363068e+18</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.364506e+18</td>\n",
       "      <td>1291.000000</td>\n",
       "      <td>7723.000000</td>\n",
       "      <td>27888.000000</td>\n",
       "      <td>756.000000</td>\n",
       "      <td>1.364506e+18</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id     replyCount   retweetCount      likeCount  \\\n",
       "count  1.174070e+05  117407.000000  117407.000000  117407.000000   \n",
       "mean   1.362062e+18       0.631410       5.045619      14.609674   \n",
       "std    1.293803e+15       9.436159      58.237370     229.083983   \n",
       "min    1.360040e+18       0.000000       0.000000       0.000000   \n",
       "25%    1.360935e+18       0.000000       0.000000       0.000000   \n",
       "50%    1.361945e+18       0.000000       0.000000       1.000000   \n",
       "75%    1.363097e+18       0.000000       1.000000       2.000000   \n",
       "max    1.364506e+18    1291.000000    7723.000000   27888.000000   \n",
       "\n",
       "          quoteCount  conversationId  retweetedTweet  \n",
       "count  117407.000000    1.174070e+05             0.0  \n",
       "mean        0.336241    1.361764e+18             NaN  \n",
       "std         4.474576    1.294352e+16             NaN  \n",
       "min         0.000000    1.981606e+10             NaN  \n",
       "25%         0.000000    1.360887e+18             NaN  \n",
       "50%         0.000000    1.361914e+18             NaN  \n",
       "75%         0.000000    1.363068e+18             NaN  \n",
       "max       756.000000    1.364506e+18             NaN  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 117407 entries, 0 to 117406\n",
      "Data columns (total 21 columns):\n",
      " #   Column           Non-Null Count   Dtype              \n",
      "---  ------           --------------   -----              \n",
      " 0   url              117407 non-null  object             \n",
      " 1   date             117407 non-null  datetime64[ns, UTC]\n",
      " 2   content          117407 non-null  object             \n",
      " 3   renderedContent  117407 non-null  object             \n",
      " 4   id               117407 non-null  int64              \n",
      " 5   user             117407 non-null  object             \n",
      " 6   outlinks         117407 non-null  object             \n",
      " 7   tcooutlinks      117407 non-null  object             \n",
      " 8   replyCount       117407 non-null  int64              \n",
      " 9   retweetCount     117407 non-null  int64              \n",
      " 10  likeCount        117407 non-null  int64              \n",
      " 11  quoteCount       117407 non-null  int64              \n",
      " 12  conversationId   117407 non-null  int64              \n",
      " 13  lang             117407 non-null  object             \n",
      " 14  source           117407 non-null  object             \n",
      " 15  sourceUrl        116495 non-null  object             \n",
      " 16  sourceLabel      116495 non-null  object             \n",
      " 17  media            28109 non-null   object             \n",
      " 18  retweetedTweet   0 non-null       float64            \n",
      " 19  quotedTweet      41436 non-null   object             \n",
      " 20  mentionedUsers   38034 non-null   object             \n",
      "dtypes: datetime64[ns, UTC](1), float64(1), int64(6), object(13)\n",
      "memory usage: 18.8+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considerando que cada registro es un tweet distinto y tiene un único identificador definido en la columna **\"id\"**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Resolvemos los siguientes desafíos:\n",
    "#### 1. Las top 10 fechas donde hay más tweets. Mencionar el usuario (username) que más publicaciones tiene por cada uno de esos días."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.A. Optimizando uso de memoria**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importamos las librerías que necesitaremos para este caso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos una función que obtenga el username de cada tweet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_username(user):\n",
    "  username = user['username']\n",
    "  return username"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variable de resultado y Diccionario para almacenar el número de publicaciones de cada usuario en cada fecha."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "result = [] # Variable de resultado\n",
    "date_user_counts = {}  # Diccionario para almacenar el número de publicaciones de cada usuario en cada fecha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Leeremos el archivo JSON en partes más pequeñas con el fin de optimizar el uso de la memoria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Leer el archivo JSON línea por línea y procesarlo en chunks\n",
    "chunk_size = 10000  # Tamaño del chunk ajustable\n",
    "reader = pd.read_json(file_path, lines=True, chunksize=chunk_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Procedemos a procesar cada parte, eliminando columnas innecesarias y realizando cálculos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for chunk in reader:\n",
    "        # Eliminar columnas innecesarias\n",
    "        chunk = chunk[['date', 'user']]\n",
    "        # Obtener username\n",
    "        chunk['username'] = chunk['user'].apply(get_username)\n",
    "\n",
    "        # Calcular el número de publicaciones de cada usuario en cada fecha en el chunk actual\n",
    "        user_counts_chunk = chunk.groupby([chunk['date'].dt.date, 'username']).size()\n",
    "\n",
    "        # Actualizar el número de publicaciones de cada usuario en cada fecha acumulado\n",
    "        for (date, username), count in user_counts_chunk.items():\n",
    "            if date not in date_user_counts:\n",
    "                date_user_counts[date] = {}\n",
    "            if username not in date_user_counts[date]:\n",
    "                date_user_counts[date][username] = 0\n",
    "            date_user_counts[date][username] += count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encontrar las 10 fechas con más tweets en todos los chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "top_10_dates = sorted(date_user_counts, key=lambda x: sum(date_user_counts[x].values()), reverse=True)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encontrar el usuario con más publicaciones para cada una de las 10 fechas principales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for date in top_10_dates:\n",
    "        # Seleccionar las ocurrencias de usuario para la fecha actual\n",
    "        user_counts_for_date = date_user_counts[date]\n",
    "        # Encontrar el usuario con más publicaciones para esta fecha\n",
    "        top_user_for_date = max(user_counts_for_date, key=user_counts_for_date.get)\n",
    "        result.append((date, top_user_for_date))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mostramos resultado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(datetime.date(2021, 2, 12), 'RanbirS00614606'), (datetime.date(2021, 2, 13), 'MaanDee08215437'), (datetime.date(2021, 2, 17), 'RaaJVinderkaur'), (datetime.date(2021, 2, 16), 'jot__b'), (datetime.date(2021, 2, 14), 'rebelpacifist'), (datetime.date(2021, 2, 18), 'neetuanjle_nitu'), (datetime.date(2021, 2, 15), 'jot__b'), (datetime.date(2021, 2, 20), 'MangalJ23056160'), (datetime.date(2021, 2, 19), 'Preetm91'), (datetime.date(2021, 2, 21), 'Surrypuria')]\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para medir el uso de la memoria utilizaremos **memory-profiler**. Para ello, completaremos el archivo **q1_memory.py** incluyendo la anotación **@profile** y procedemos a ejecutarlo con el siguiente comando en un terminal:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(base) jupyter@instance-20240323-093523:~/gcp-demo/src$ python -m memory_profiler q1_memory.py**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "q1_memory.py"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from typing import List, Tuple\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "\n",
    "# Función para obtener username del tweet\n",
    "def get_username(user):\n",
    "    return user['username']\n",
    "\n",
    "@profile\n",
    "def q1_memory(file_path: str) -> List[Tuple[datetime.date, str]]:\n",
    "    result = []\n",
    "    date_user_counts = {}  # Diccionario para almacenar el número de publicaciones de cada usuario en cada fecha\n",
    "\n",
    "    # Leer el archivo JSON línea por línea y procesarlo en chunks\n",
    "    chunk_size = 10000  # Tamaño del chunk ajustable\n",
    "    reader = pd.read_json(file_path, lines=True, chunksize=chunk_size)\n",
    "    \n",
    "    for chunk in reader:\n",
    "        # Eliminar columnas innecesarias\n",
    "        chunk = chunk[['date', 'user']]\n",
    "        # Obtener username\n",
    "        chunk['username'] = chunk['user'].apply(get_username)\n",
    "\n",
    "        # Calcular el número de publicaciones de cada usuario en cada fecha en el chunk actual\n",
    "        user_counts_chunk = chunk.groupby([chunk['date'].dt.date, 'username']).size()\n",
    "\n",
    "        # Actualizar el número de publicaciones de cada usuario en cada fecha acumulado\n",
    "        for (date, username), count in user_counts_chunk.items():\n",
    "            if date not in date_user_counts:\n",
    "                date_user_counts[date] = {}\n",
    "            if username not in date_user_counts[date]:\n",
    "                date_user_counts[date][username] = 0\n",
    "            date_user_counts[date][username] += count\n",
    "\n",
    "    # Encontrar las 10 fechas con más tweets en todos los chunks\n",
    "    top_10_dates = sorted(date_user_counts, key=lambda x: sum(date_user_counts[x].values()), reverse=True)[:10]\n",
    "\n",
    "    # Encontrar el usuario con más publicaciones para cada una de las 10 fechas principales\n",
    "    for date in top_10_dates:\n",
    "        # Seleccionar las ocurrencias de usuario para la fecha actual\n",
    "        user_counts_for_date = date_user_counts[date]\n",
    "        # Encontrar el usuario con más publicaciones para esta fecha\n",
    "        top_user_for_date = max(user_counts_for_date, key=user_counts_for_date.get)\n",
    "        result.append((date, top_user_for_date))\n",
    "\n",
    "    return result\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    file_path = \"gs://challenge-de/farmers-protest-tweets-2021-2-4.json\"\n",
    "    print(q1_memory(file_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "[(datetime.date(2021, 2, 12), 'RanbirS00614606'), (datetime.date(2021, 2, 13), 'MaanDee08215437'), (datetime.date(2021, 2, 17), 'RaaJVinderkaur'), (datetime.date(2021, 2, 16), 'jot__b'), (datetime.date(2021, 2, 14), 'rebelpacifist'), (datetime.date(2021, 2, 18), 'neetuanjle_nitu'), (datetime.date(2021, 2, 15), 'jot__b'), (datetime.date(2021, 2, 20), 'MangalJ23056160'), (datetime.date(2021, 2, 23), 'Surrypuria'), (datetime.date(2021, 2, 19), 'Preetm91')]\n",
    "Filename: q1_memory.py\n",
    "\n",
    "Line #    Mem usage    Increment  Occurrences   Line Contents\n",
    "=============================================================\n",
    "     9  122.980 MiB  122.980 MiB           1   @profile\n",
    "    10                                         def q1_memory(file_path: str) -> List[Tuple[datetime.date, str]]:\n",
    "    11  122.980 MiB    0.000 MiB           1       result = []\n",
    "    12  122.980 MiB    0.000 MiB           1       date_user_counts = {}  # Diccionario para almacenar el número de publicaciones de cada usuario en cada fecha\n",
    "    13                                         \n",
    "    14                                             # Leer el archivo JSON línea por línea y procesarlo en chunks\n",
    "    15  122.980 MiB    0.000 MiB           1       chunk_size = 10000  # Tamaño del chunk ajustable\n",
    "    16  145.441 MiB   22.461 MiB           1       reader = pd.read_json(file_path, lines=True, chunksize=chunk_size)\n",
    "    17                                             \n",
    "    18  371.988 MiB  220.438 MiB          13       for chunk in reader:\n",
    "    19                                                 # Eliminar columnas innecesarias\n",
    "    20  371.988 MiB   -6.109 MiB          12           chunk = chunk[['date', 'user']]\n",
    "    21                                                 # Obtener username\n",
    "    22  371.988 MiB   -6.109 MiB          12           chunk['username'] = chunk['user'].apply(get_username)\n",
    "    23                                         \n",
    "    24                                                 # Calcular el número de publicaciones de cada usuario en cada fecha en el chunk actual\n",
    "    25  371.988 MiB   -6.109 MiB          12           user_counts_chunk = chunk.groupby([chunk['date'].dt.date, 'username']).size()\n",
    "    26                                         \n",
    "    27                                                 # Actualizar el número de publicaciones de cada usuario en cada fecha acumulado\n",
    "    28  371.988 MiB -29659.336 MiB       56480           for (date, username), count in user_counts_chunk.items():\n",
    "    29  371.988 MiB -29653.227 MiB       56468               if date not in date_user_counts:\n",
    "    30  371.988 MiB   -6.109 MiB          13                   date_user_counts[date] = {}\n",
    "    31  371.988 MiB -29653.227 MiB       56468               if username not in date_user_counts[date]:\n",
    "    32  371.988 MiB -26877.484 MiB       51646                   date_user_counts[date][username] = 0\n",
    "    33  371.988 MiB -29653.227 MiB       56468               date_user_counts[date][username] += count\n",
    "    34                                         \n",
    "    35                                             # Encontrar las 10 fechas con más tweets en todos los chunks\n",
    "    36  371.988 MiB    0.000 MiB          27       top_10_dates = sorted(date_user_counts, key=lambda x: sum(date_user_counts[x].values()), reverse=True)[:10]\n",
    "    37                                         \n",
    "    38                                             # Encontrar el usuario con más publicaciones para cada una de las 10 fechas principales\n",
    "    39  371.988 MiB    0.000 MiB          11       for date in top_10_dates:\n",
    "    40                                                 # Seleccionar las ocurrencias de usuario para la fecha actual\n",
    "    41  371.988 MiB    0.000 MiB          10           user_counts_for_date = date_user_counts[date]\n",
    "    42                                                 # Encontrar el usuario con más publicaciones para esta fecha\n",
    "    43  371.988 MiB    0.000 MiB          10           top_user_for_date = max(user_counts_for_date, key=user_counts_for_date.get)\n",
    "    44  371.988 MiB    0.000 MiB          10           result.append((date, top_user_for_date))\n",
    "    45                                         \n",
    "    46  371.988 MiB    0.000 MiB           1       return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.B. Optimizando tiempo de ejecución**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para medir los tiempos de ejecución utilizaremos **Python Profilers**. Para ello, debemos importar la siguientes librerías:<br>\n",
    "**cProfile<br>\n",
    "pstats**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Además implemententamos la función **q1_time**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from typing import List, Tuple\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import cProfile\n",
    "import pstats\n",
    "\n",
    "# Función para obtener username del tweet\n",
    "def get_username(user):\n",
    "    return user['username']\n",
    "\n",
    "def q1_time(file_path: str) -> List[Tuple[datetime.date, str]]:\n",
    "    result = []\n",
    "    date_user_counts = {}  # Diccionario para almacenar el número de publicaciones de cada usuario en cada fecha\n",
    "\n",
    "    # Leer el archivo JSON línea por línea y procesarlo en chunks\n",
    "    chunk_size = 10000  # Tamaño del chunk ajustable\n",
    "    reader = pd.read_json(file_path, lines=True, chunksize=chunk_size)\n",
    "    \n",
    "    for chunk in reader:\n",
    "        # Eliminar columnas innecesarias\n",
    "        chunk = chunk[['date', 'user']]\n",
    "        # Obtener username\n",
    "        chunk['username'] = chunk['user'].apply(get_username)\n",
    "\n",
    "        # Calcular el número de publicaciones de cada usuario en cada fecha en el chunk actual\n",
    "        user_counts_chunk = chunk.groupby([chunk['date'].dt.date, 'username']).size()\n",
    "\n",
    "        # Actualizar el número de publicaciones de cada usuario en cada fecha acumulado\n",
    "        for (date, username), count in user_counts_chunk.items():\n",
    "            if date not in date_user_counts:\n",
    "                date_user_counts[date] = {}\n",
    "            if username not in date_user_counts[date]:\n",
    "                date_user_counts[date][username] = 0\n",
    "            date_user_counts[date][username] += count\n",
    "\n",
    "    # Encontrar las 10 fechas con más tweets en todos los chunks\n",
    "    top_10_dates = sorted(date_user_counts, key=lambda x: sum(date_user_counts[x].values()), reverse=True)[:10]\n",
    "\n",
    "    # Encontrar el usuario con más publicaciones para cada una de las 10 fechas principales\n",
    "    for date in top_10_dates:\n",
    "        # Seleccionar las ocurrencias de usuario para la fecha actual\n",
    "        user_counts_for_date = date_user_counts[date]\n",
    "        # Encontrar el usuario con más publicaciones para esta fecha\n",
    "        top_user_for_date = max(user_counts_for_date, key=user_counts_for_date.get)\n",
    "        result.append((date, top_user_for_date))\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Para obtener el tiempo total de ejecución, ejecutamos el siguiente código llamando a la función **q1_time**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1546848 function calls in 32.638454596 seconds\n"
     ]
    }
   ],
   "source": [
    "# Ejecuta la función dentro del perfilador y guarda los resultados\n",
    "profiler = cProfile.Profile()\n",
    "profiler.enable()\n",
    "file_path = \"gs://challenge-de/farmers-protest-tweets-2021-2-4.json\"\n",
    "q1_time(file_path)\n",
    "profiler.disable()\n",
    "\n",
    "# Genera estadísticas a partir del perfil\n",
    "stats = pstats.Stats(profiler)\n",
    "# Imprime el resumen con el número total de llamadas y el tiempo total de ejecución\n",
    "print(stats.total_calls, \"function calls in\", stats.total_tt, \"seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para mejorar los tiempos de ejecución no dividiremos el JSON en partes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from typing import List, Tuple\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import cProfile\n",
    "import pstats\n",
    "\n",
    "def get_username(user):\n",
    "  return user['username']\n",
    "\n",
    "def q1_time(file_path: str) -> List[Tuple[datetime.date, str]]:\n",
    "    result = []\n",
    "    \n",
    "    # Leer el archivo JSON línea por línea\n",
    "    df = pd.read_json(file_path, lines=True)\n",
    "    \n",
    "    # Eliminar columnas innecesarias\n",
    "    df = df[['date', 'user']] \n",
    "    \n",
    "    # Obtener username\n",
    "    df['username'] = df['user'].apply(get_username)\n",
    "\n",
    "    # Calcular las 10 fechas con más tweets\n",
    "    top_10_dates = pd.Series([date.date() for date in df['date']]).value_counts().index[:10]\n",
    "\n",
    "    # Encontrar el usuario con más publicaciones para cada una de las 10 fechas principales en el chunk actual\n",
    "    for date in top_10_dates:\n",
    "        # Filtrar el DataFrame por fecha\n",
    "        tweets_for_date = df[df['date'].dt.date == date]\n",
    "        # Encontrar el usuario con más publicaciones para esta fecha\n",
    "        top_user_for_date = tweets_for_date['username'].value_counts().idxmax()\n",
    "        result.append((date, top_user_for_date))\n",
    "     \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "777968 function calls in 16.906431455999993 seconds\n"
     ]
    }
   ],
   "source": [
    "# Ejecuta la función dentro del perfilador y guarda los resultados\n",
    "profiler = cProfile.Profile()\n",
    "profiler.enable()\n",
    "file_path = \"gs://challenge-de/farmers-protest-tweets-2021-2-4.json\"\n",
    "q1_time(file_path)\n",
    "profiler.disable()\n",
    "\n",
    "# Genera estadísticas a partir del perfil\n",
    "stats = pstats.Stats(profiler)\n",
    "# Imprime el resumen con el número total de llamadas y el tiempo total de ejecución\n",
    "print(stats.total_calls, \"function calls in\", stats.total_tt, \"seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entonces completaremos el archivo q1_time.py y procedemos a ejecutarlo con el siguiente comando en un terminal:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(base) jupyter@instance-20240323-093523:~/gcp-demo/src$ python q1_time.py**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "q1_time.py"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from typing import List, Tuple\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import cProfile\n",
    "import pstats\n",
    "\n",
    "def get_username(user):\n",
    "  return user['username']\n",
    "\n",
    "def q1_time(file_path: str) -> List[Tuple[datetime.date, str]]:\n",
    "    result = []\n",
    "    \n",
    "    # Leer el archivo JSON línea por línea\n",
    "    df = pd.read_json(file_path, lines=True)\n",
    "    \n",
    "    # Eliminar columnas innecesarias\n",
    "    df = df[['date', 'user']] \n",
    "    \n",
    "    # Obtener username\n",
    "    df['username'] = df['user'].apply(get_username)\n",
    "\n",
    "    # Calcular las 10 fechas con más tweets\n",
    "    top_10_dates = pd.Series([date.date() for date in df['date']]).value_counts().index[:10]\n",
    "\n",
    "    # Encontrar el usuario con más publicaciones para cada una de las 10 fechas principales en el chunk actual\n",
    "    for date in top_10_dates:\n",
    "        # Filtrar el DataFrame por fecha\n",
    "        tweets_for_date = df[df['date'].dt.date == date]\n",
    "        # Encontrar el usuario con más publicaciones para esta fecha\n",
    "        top_user_for_date = tweets_for_date['username'].value_counts().idxmax()\n",
    "        result.append((date, top_user_for_date))\n",
    "     \n",
    "    return result\n",
    "\n",
    "# Ejecuta la función dentro del perfilador y guarda los resultados\n",
    "profiler = cProfile.Profile()\n",
    "profiler.enable()\n",
    "file_path = \"gs://challenge-de/farmers-protest-tweets-2021-2-4.json\"\n",
    "q1_time(file_path)\n",
    "profiler.disable()\n",
    "\n",
    "# Genera estadísticas a partir del perfil\n",
    "stats = pstats.Stats(profiler)\n",
    "# Imprime el resumen con el número total de llamadas y el tiempo total de ejecución\n",
    "print(stats.total_calls, \"function calls in\", stats.total_tt, \"seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "1065040 function calls in 17.708120856000065 seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Los top 10 emojis más usados con su respectivo conteo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.A. Optimizando uso de memoria**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para identificar los emojis, se esta definiendo la siguiente expresión regular."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "tags": []
   },
   "source": [
    "    \"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "    \"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "    \"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "    \"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "    \"\\U0001F700-\\U0001F77F\"  # alchemical symbols\n",
    "    \"\\U0001F780-\\U0001F7FF\"  # Geometric Shapes Extended\n",
    "    \"\\U0001F800-\\U0001F8FF\"  # Supplemental Arrows-C\n",
    "    \"\\U0001F900-\\U0001F9FF\"  # Supplemental Symbols and Pictographs\n",
    "    \"\\U0001FA00-\\U0001FA6F\"  # Chess Symbols\n",
    "    \"\\U0001FA70-\\U0001FAFF\"  # Symbols and Pictographs Extended-A\n",
    "    \"\\U00002702-\\U000027B0\"  # Dingbats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importamos librerías que utilizaremos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from typing import List, Tuple\n",
    "import re\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "from google.cloud import storage\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Función para extraer emojis de un tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extract_emojis(tweet):\n",
    "    # Expresión regular para encontrar emojis en un tweet\n",
    "    emoji_regex = re.compile(r':\\w+:|[\\U0001F1E0-\\U0001F1FF]|[\\U0001F300-\\U0001F5FF]|[\\U0001F600-\\U0001F64F]|[\\U0001F680-\\U0001F6FF]|[\\U0001F700-\\U0001F77F]|[\\U0001F780-\\U0001F7FF]|[\\U0001F800-\\U0001F8FF]|[\\U0001F900-\\U0001F9FF]|[\\U0001FA00-\\U0001FA6F]|[\\U0001FA70-\\U0001FAFF]|[\\U00002702-\\U000027B0]', flags=re.UNICODE)\n",
    "    return emoji_regex.findall(tweet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Función principal para contar los emojis más utilizados en los tweets.\n",
    "1. Primero descargamos el JSON desde el bucket de GCS hacia el entorno local de manera temporal.\n",
    "2. Finalmente realizamos las operaciones necesarias para obtener los 10 emojis más utilizados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def q2_memory(file_path: str) -> List[Tuple[str, int]]:\n",
    "\n",
    "    # Inicializar cliente de Google Cloud Storage\n",
    "    client = storage.Client()\n",
    "\n",
    "    # Obtener el nombre del bucket y del blob del archivo\n",
    "    bucket_name, blob_name = file_path.replace(\"gs://\", \"\").split(\"/\", 1)\n",
    "\n",
    "    # Obtener el bucket\n",
    "    bucket = client.bucket(bucket_name)\n",
    "\n",
    "    # Obtener el blob\n",
    "    blob = bucket.blob(blob_name)\n",
    "\n",
    "    # Descargar el archivo a un archivo temporal\n",
    "    with open(\"/tmp/temp.json\", \"wb\") as f:\n",
    "        blob.download_to_file(f)\n",
    "\n",
    "    # Contador para contar la frecuencia de cada emoji\n",
    "    emoji_counts = Counter()\n",
    "    with open(\"/tmp/temp.json\", 'r', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            tweet = json.loads(line)\n",
    "            # Extraer emojis del contenido del tweet\n",
    "            emojis = extract_emojis(tweet['content'].lower())\n",
    "            # Actualizar el contador de emojis\n",
    "            emoji_counts.update(emojis)\n",
    "    \n",
    "    # Obtener los 10 emojis más utilizados\n",
    "    most_used_emojis = emoji_counts.most_common(10)\n",
    "    return most_used_emojis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejecutamos la función principal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('🙏', 7286), ('😂', 3072), ('🚜', 2972), ('✊', 2411), ('🌾', 2363), ('🇮', 2096), ('🇳', 2094), ('🏻', 2080), ('❤', 1779), ('🤣', 1668)]\n"
     ]
    }
   ],
   "source": [
    "# Llamar a la función principal e imprimir los resultados\n",
    "print(q2_memory(file_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Medimos la memoria en uso a **q2_memory.py**, incluimos la anotación **@profile**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(base) jupyter@instance-20240323-093523:~/gcp-demo/src$ python -m memory_profiler q2_memory.py**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "q2_memory.py"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from typing import List, Tuple\n",
    "import re\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "from google.cloud import storage\n",
    "import json\n",
    "\n",
    "# Función para extraer emojis de un tweet\n",
    "def extract_emojis(tweet):\n",
    "    # Expresión regular para encontrar emojis en un tweet\n",
    "    emoji_regex = re.compile(r':\\w+:|[\\U0001F1E0-\\U0001F1FF]|[\\U0001F300-\\U0001F5FF]|[\\U0001F600-\\U0001F64F]|[\\U0001F680-\\U0001F6FF]|[\\U0001F700-\\U0001F77F]|[\\U0001F780-\\U0001F7FF]|[\\U0001F800-\\U0001F8FF]|[\\U0001F900-\\U0001F9FF]|[\\U0001FA00-\\U0001FA6F]|[\\U0001FA70-\\U0001FAFF]|[\\U00002702-\\U000027B0]', flags=re.UNICODE)\n",
    "    return emoji_regex.findall(tweet)\n",
    "\n",
    "# Función principal para contar los emojis más utilizados en los tweets\n",
    "@profile\n",
    "def q2_memory(file_path: str) -> List[Tuple[str, int]]:\n",
    "\n",
    "    # Inicializar cliente de Google Cloud Storage\n",
    "    client = storage.Client()\n",
    "\n",
    "    # Obtener el nombre del bucket y del blob del archivo\n",
    "    bucket_name, blob_name = file_path.replace(\"gs://\", \"\").split(\"/\", 1)\n",
    "\n",
    "    # Obtener el bucket\n",
    "    bucket = client.bucket(bucket_name)\n",
    "\n",
    "    # Obtener el blob\n",
    "    blob = bucket.blob(blob_name)\n",
    "\n",
    "    # Descargar el archivo a un archivo temporal\n",
    "    with open(\"/tmp/temp.json\", \"wb\") as f:\n",
    "        blob.download_to_file(f)\n",
    "\n",
    "    # Contador para contar la frecuencia de cada emoji\n",
    "    emoji_counts = Counter()\n",
    "    with open(\"/tmp/temp.json\", 'r', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            tweet = json.loads(line)\n",
    "            # Extraer emojis del contenido del tweet\n",
    "            emojis = extract_emojis(tweet['content'].lower())\n",
    "            # Actualizar el contador de emojis\n",
    "            emoji_counts.update(emojis)\n",
    "    \n",
    "    # Obtener los 10 emojis más utilizados\n",
    "    most_used_emojis = emoji_counts.most_common(10)\n",
    "    return most_used_emojis\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Ruta del archivo JSON en Google Cloud Storage\n",
    "    file_path = \"gs://challenge-de/farmers-protest-tweets-2021-2-4.json\"\n",
    "    # Llamar a la función principal e imprimir los resultados\n",
    "    print(q2_memory(file_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "[('🙏', 7286), ('😂', 3072), ('🚜', 2972), ('✊', 2411), ('🌾', 2363), ('🇮', 2096), ('🇳', 2094), ('🏻', 2080), ('❤', 1779), ('🤣', 1668)]\n",
    "Filename: q2_memory.py\n",
    "\n",
    "Line #    Mem usage    Increment  Occurrences   Line Contents\n",
    "=============================================================\n",
    "    15  143.375 MiB  143.375 MiB           1   @profile\n",
    "    16                                         def q2_memory(file_path: str) -> List[Tuple[str, int]]:\n",
    "    17                                         \n",
    "    18                                             # Inicializar cliente de Google Cloud Storage\n",
    "    19  143.867 MiB    0.492 MiB           1       client = storage.Client()\n",
    "    20                                         \n",
    "    21                                             # Obtener el nombre del bucket y del blob del archivo\n",
    "    22  143.867 MiB    0.000 MiB           1       bucket_name, blob_name = file_path.replace(\"gs://\", \"\").split(\"/\", 1)\n",
    "    23                                         \n",
    "    24                                             # Obtener el bucket\n",
    "    25  143.867 MiB    0.000 MiB           1       bucket = client.bucket(bucket_name)\n",
    "    26                                         \n",
    "    27                                             # Obtener el blob\n",
    "    28  143.867 MiB    0.000 MiB           1       blob = bucket.blob(blob_name)\n",
    "    29                                         \n",
    "    30                                             # Descargar el archivo a un archivo temporal\n",
    "    31  145.879 MiB    0.000 MiB           2       with open(\"/tmp/temp.json\", \"wb\") as f:\n",
    "    32  145.879 MiB    2.012 MiB           1           blob.download_to_file(f)\n",
    "    33                                         \n",
    "    34                                             # Contador para contar la frecuencia de cada emoji\n",
    "    35  145.879 MiB    0.000 MiB           1       emoji_counts = Counter()\n",
    "    36  146.742 MiB    0.000 MiB           2       with open(\"/tmp/temp.json\", 'r', encoding='utf-8') as file:\n",
    "    37  146.742 MiB    0.000 MiB      117408           for line in file:\n",
    "    38  146.742 MiB    0.258 MiB      117407               tweet = json.loads(line)\n",
    "    39                                                     # Extraer emojis del contenido del tweet\n",
    "    40  146.742 MiB    0.605 MiB      117407               emojis = extract_emojis(tweet['content'].lower())\n",
    "    41                                                     # Actualizar el contador de emojis\n",
    "    42  146.742 MiB    0.000 MiB      117407               emoji_counts.update(emojis)\n",
    "    43                                             \n",
    "    44                                             # Obtener los 10 emojis más utilizados\n",
    "    45  146.742 MiB    0.000 MiB           1       most_used_emojis = emoji_counts.most_common(10)\n",
    "    46  146.742 MiB    0.000 MiB           1       return most_used_emojis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.B. Optimizando tiempo de ejecución**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para calcular el tiempo de ejecución importamos cProfile y pstats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5542728 function calls in 16.481421864000005 seconds\n"
     ]
    }
   ],
   "source": [
    "import cProfile\n",
    "import pstats\n",
    "\n",
    "# Ejecuta la función dentro del perfilador y guarda los resultados\n",
    "profiler = cProfile.Profile()\n",
    "profiler.enable()\n",
    "q2_memory(file_path)\n",
    "profiler.disable()\n",
    "\n",
    "# Genera estadísticas a partir del perfil\n",
    "stats = pstats.Stats(profiler)\n",
    "# Imprime el resumen con el número total de llamadas y el tiempo total de ejecución\n",
    "print(stats.total_calls, \"function calls in\", stats.total_tt, \"seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entonces completaremos el archivo **q2_time.py** y procedemos a ejecutarlo con el siguiente comando en un terminal:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(base) jupyter@instance-20240323-093523:~/gcp-demo/src$ python q2_time.py**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "q2_time.py"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from typing import List, Tuple\n",
    "from datetime import datetime\n",
    "import re\n",
    "from collections import Counter\n",
    "from google.cloud import storage\n",
    "import json\n",
    "import cProfile\n",
    "import pstats\n",
    "\n",
    "# Función para extraer emojis de un tweet\n",
    "def extract_emojis(tweet):\n",
    "    # Expresión regular para encontrar emojis en un tweet\n",
    "    emoji_regex = re.compile(r':\\w+:|[\\U0001F1E0-\\U0001F1FF]|[\\U0001F300-\\U0001F5FF]|[\\U0001F600-\\U0001F64F]|[\\U0001F680-\\U0001F6FF]|[\\U0001F700-\\U0001F77F]|[\\U0001F780-\\U0001F7FF]|[\\U0001F800-\\U0001F8FF]|[\\U0001F900-\\U0001F9FF]|[\\U0001FA00-\\U0001FA6F]|[\\U0001FA70-\\U0001FAFF]|[\\U00002702-\\U000027B0]', flags=re.UNICODE)\n",
    "    return emoji_regex.findall(tweet)\n",
    "\n",
    "# Función principal para contar los emojis más utilizados en los tweets\n",
    "def q2_time(file_path: str) -> List[Tuple[datetime.date, str]]:\n",
    "\n",
    "    # Inicializar cliente de Google Cloud Storage\n",
    "    client = storage.Client()\n",
    "\n",
    "    # Obtener el nombre del bucket y del blob del archivo\n",
    "    bucket_name, blob_name = file_path.replace(\"gs://\", \"\").split(\"/\", 1)\n",
    "\n",
    "    # Obtener el bucket\n",
    "    bucket = client.bucket(bucket_name)\n",
    "\n",
    "    # Obtener el blob\n",
    "    blob = bucket.blob(blob_name)\n",
    "\n",
    "    # Descargar el archivo a un archivo temporal\n",
    "    with open(\"/tmp/temp.json\", \"wb\") as f:\n",
    "        blob.download_to_file(f)\n",
    "\n",
    "    # Contador para contar la frecuencia de cada emoji\n",
    "    emoji_counts = Counter()\n",
    "    with open(\"/tmp/temp.json\", 'r', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            tweet = json.loads(line)\n",
    "            # Extraer emojis del contenido del tweet\n",
    "            emojis = extract_emojis(tweet['content'].lower())\n",
    "            # Actualizar el contador de emojis\n",
    "            emoji_counts.update(emojis)\n",
    "    \n",
    "    # Obtener los 10 emojis más utilizados\n",
    "    most_used_emojis = emoji_counts.most_common(10)\n",
    "    return most_used_emojis\n",
    "\n",
    "# Ejecuta la función dentro del perfilador y guarda los resultados\n",
    "profiler = cProfile.Profile()\n",
    "profiler.enable()\n",
    "file_path = \"gs://challenge-de/farmers-protest-tweets-2021-2-4.json\"\n",
    "q2_time(file_path)\n",
    "profiler.disable()\n",
    "\n",
    "# Genera estadísticas a partir del perfil\n",
    "stats = pstats.Stats(profiler)\n",
    "# Imprime el resumen con el número total de llamadas y el tiempo total de ejecución\n",
    "print(stats.total_calls, \"function calls in\", stats.total_tt, \"seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "5574905 function calls in 14.18106106399998 seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. El top 10 histórico de usuarios (username) más influyentes en función del conteo de las menciones (@) que registra cada uno de ellos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.A. Optimizando uso de memoria**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importamos la librerías que necesitaremos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from typing import List, Tuple\n",
    "from google.cloud import storage\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementamos la función que obtendrá el archivo del bucket de GCS y calculará el TOP 10 de usuarios mencionados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def q3_memory(file_path: str) -> List[Tuple[str, int]]:\n",
    "    # Inicializar un diccionario para almacenar la frecuencia de los nombres de usuario\n",
    "    username_count = {}\n",
    "\n",
    "    # Inicializar el cliente de Google Cloud Storage\n",
    "    client = storage.Client()\n",
    "\n",
    "    # Obtener el nombre del bucket y el nombre del objeto\n",
    "    bucket_name, blob_name = file_path.replace(\"gs://\", \"\").split(\"/\", 1)\n",
    "\n",
    "    # Obtener el bucket\n",
    "    bucket = client.bucket(bucket_name)\n",
    "\n",
    "    # Obtener el blob\n",
    "    blob = bucket.blob(blob_name)\n",
    "\n",
    "    # Leer el archivo línea por línea\n",
    "    with blob.open(\"r\") as file:\n",
    "        for line in file:\n",
    "            tweet = json.loads(line)\n",
    "            mentioned_users = tweet.get('mentionedUsers')  # Obtener la lista de usuarios mencionados\n",
    "            if mentioned_users is not None:\n",
    "                for user in mentioned_users:\n",
    "                    username = user.get('username')\n",
    "                    if username:  # Verificar si se proporciona un nombre de usuario\n",
    "                        # Incrementar el contador para este nombre de usuario\n",
    "                        username_count[username] = username_count.get(username, 0) + 1\n",
    "\n",
    "    # Ordenar el diccionario por la frecuencia de menciones en orden descendente\n",
    "    sorted_username_count = sorted(username_count.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Tomar los top 10 usuarios más mencionados\n",
    "    top_10_users = sorted_username_count[:10]\n",
    "\n",
    "    return top_10_users"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mostramos los resultados de la función"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('narendramodi', 2265), ('Kisanektamorcha', 1840), ('RakeshTikaitBKU', 1644), ('PMOIndia', 1427), ('RahulGandhi', 1146), ('GretaThunberg', 1048), ('RaviSinghKA', 1019), ('rihanna', 986), ('UNHumanRights', 962), ('meenaharris', 926)]\n"
     ]
    }
   ],
   "source": [
    "print(q3_memory(file_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Medimos la memoria en uso a q2_memory.py, incluimos la anotación @profile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(base) jupyter@instance-20240323-093523:~/gcp-demo/src$ python -m memory_profiler q3_memory.py**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "q3_memory.py"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from typing import List, Tuple\n",
    "from google.cloud import storage\n",
    "import json\n",
    "\n",
    "@profile\n",
    "def q3_memory(file_path: str) -> List[Tuple[str, int]]:\n",
    "    # Inicializar un diccionario para almacenar la frecuencia de los nombres de usuario\n",
    "    username_count = {}\n",
    "\n",
    "    # Inicializar el cliente de Google Cloud Storage\n",
    "    client = storage.Client()\n",
    "\n",
    "    # Obtener el nombre del bucket y el nombre del objeto\n",
    "    bucket_name, blob_name = file_path.replace(\"gs://\", \"\").split(\"/\", 1)\n",
    "\n",
    "    # Obtener el bucket\n",
    "    bucket = client.bucket(bucket_name)\n",
    "\n",
    "    # Obtener el blob\n",
    "    blob = bucket.blob(blob_name)\n",
    "\n",
    "    # Leer el archivo línea por línea\n",
    "    with blob.open(\"r\") as file:\n",
    "        for line in file:\n",
    "            tweet = json.loads(line)\n",
    "            mentioned_users = tweet.get('mentionedUsers')  # Obtener la lista de usuarios mencionados\n",
    "            if mentioned_users is not None:\n",
    "                for user in mentioned_users:\n",
    "                    username = user.get('username')\n",
    "                    if username:  # Verificar si se proporciona un nombre de usuario\n",
    "                        # Incrementar el contador para este nombre de usuario\n",
    "                        username_count[username] = username_count.get(username, 0) + 1\n",
    "\n",
    "    # Ordenar el diccionario por la frecuencia de menciones en orden descendente\n",
    "    sorted_username_count = sorted(username_count.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Tomar los top 10 usuarios más mencionados\n",
    "    top_10_users = sorted_username_count[:10]\n",
    "\n",
    "    return top_10_users\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    file_path = \"gs://challenge-de/farmers-protest-tweets-2021-2-4.json\"\n",
    "    print(q3_memory(file_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "[('narendramodi', 2265), ('Kisanektamorcha', 1840), ('RakeshTikaitBKU', 1644), ('PMOIndia', 1427), ('RahulGandhi', 1146), ('GretaThunberg', 1048), ('RaviSinghKA', 1019), ('rihanna', 986), ('UNHumanRights', 962), ('meenaharris', 926)]\n",
    "Filename: q3_memory2.py\n",
    "\n",
    "Line #    Mem usage    Increment  Occurrences   Line Contents\n",
    "=============================================================\n",
    "     5   65.465 MiB   65.465 MiB           1   @profile\n",
    "     6                                         def q3_memory(file_path: str) -> List[Tuple[str, int]]:\n",
    "     7                                             # Inicializar un diccionario para almacenar la frecuencia de los nombres de usuario\n",
    "     8   65.465 MiB    0.000 MiB           1       username_count = {}\n",
    "     9                                         \n",
    "    10                                             # Inicializar el cliente de Google Cloud Storage\n",
    "    11   65.887 MiB    0.422 MiB           1       client = storage.Client()\n",
    "    12                                         \n",
    "    13                                             # Obtener el nombre del bucket y el nombre del objeto\n",
    "    14   65.887 MiB    0.000 MiB           1       bucket_name, blob_name = file_path.replace(\"gs://\", \"\").split(\"/\", 1)\n",
    "    15                                         \n",
    "    16                                             # Obtener el bucket\n",
    "    17   65.887 MiB    0.000 MiB           1       bucket = client.bucket(bucket_name)\n",
    "    18                                         \n",
    "    19                                             # Obtener el blob\n",
    "    20   65.887 MiB    0.000 MiB           1       blob = bucket.blob(blob_name)\n",
    "    21                                         \n",
    "    22                                             # Leer el archivo línea por línea\n",
    "    23   99.555 MiB  -28.781 MiB           2       with blob.open(\"r\") as file:\n",
    "    24  128.336 MiB  -23.895 MiB      117408           for line in file:\n",
    "    25  128.336 MiB  -57.562 MiB      117407               tweet = json.loads(line)\n",
    "    26  128.336 MiB  -57.562 MiB      117407               mentioned_users = tweet.get('mentionedUsers')  # Obtener la lista de usuarios mencionados\n",
    "    27  128.336 MiB  -57.562 MiB      117407               if mentioned_users is not None:\n",
    "    28  128.336 MiB  -57.562 MiB      141437                   for user in mentioned_users:\n",
    "    29  128.336 MiB  -28.781 MiB      103403                       username = user.get('username')\n",
    "    30  128.336 MiB  -28.781 MiB      103403                       if username:  # Verificar si se proporciona un nombre de usuario\n",
    "    31                                                                 # Incrementar el contador para este nombre de usuario\n",
    "    32  128.336 MiB  -28.781 MiB      103403                           username_count[username] = username_count.get(username, 0) + 1\n",
    "    33                                         \n",
    "    34                                             # Ordenar el diccionario por la frecuencia de menciones en orden descendente\n",
    "    35  100.324 MiB    0.770 MiB       30479       sorted_username_count = sorted(username_count.items(), key=lambda x: x[1], reverse=True)\n",
    "    36                                         \n",
    "    37                                             # Tomar los top 10 usuarios más mencionados\n",
    "    38  100.324 MiB    0.000 MiB           1       top_10_users = sorted_username_count[:10]\n",
    "    39                                         \n",
    "    40  100.324 MiB    0.000 MiB           1       return top_10_users"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.B. Optimizando tiempo de ejecución**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para calcular el tiempo de ejecución importamos cProfile y pstats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4965666 function calls in 10.628746484999985 seconds\n"
     ]
    }
   ],
   "source": [
    "# Ejecuta la función dentro del perfilador y guarda los resultados\n",
    "profiler = cProfile.Profile()\n",
    "profiler.enable()\n",
    "file_path = \"gs://challenge-de/farmers-protest-tweets-2021-2-4.json\"\n",
    "q3_memory(file_path)\n",
    "profiler.disable()\n",
    "\n",
    "# Genera estadísticas a partir del perfil\n",
    "stats = pstats.Stats(profiler)\n",
    "# Imprime el resumen con el número total de llamadas y el tiempo total de ejecución\n",
    "print(stats.total_calls, \"function calls in\", stats.total_tt, \"seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entonces completaremos el archivo q3_time.py y procedemos a ejecutarlo con el siguiente comando en un terminal:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "**(base) jupyter@instance-20240323-093523:~/gcp-demo/src$ python q3_time.py**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "q3_time.py"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from typing import List, Tuple\n",
    "from google.cloud import storage\n",
    "import json\n",
    "import cProfile\n",
    "import pstats\n",
    "\n",
    "def q3_time(file_path: str) -> List[Tuple[str, int]]:\n",
    "    # Inicializar un diccionario para almacenar la frecuencia de los nombres de usuario\n",
    "    username_count = {}\n",
    "\n",
    "    # Inicializar el cliente de Google Cloud Storage\n",
    "    client = storage.Client()\n",
    "\n",
    "    # Obtener el nombre del bucket y el nombre del objeto\n",
    "    bucket_name, blob_name = file_path.replace(\"gs://\", \"\").split(\"/\", 1)\n",
    "\n",
    "    # Obtener el bucket\n",
    "    bucket = client.bucket(bucket_name)\n",
    "\n",
    "    # Obtener el blob\n",
    "    blob = bucket.blob(blob_name)\n",
    "\n",
    "    # Leer el archivo línea por línea\n",
    "    with blob.open(\"r\") as file:\n",
    "        for line in file:\n",
    "            tweet = json.loads(line)\n",
    "            mentioned_users = tweet.get('mentionedUsers')  # Obtener la lista de usuarios mencionados\n",
    "            if mentioned_users is not None:\n",
    "                for user in mentioned_users:\n",
    "                    username = user.get('username')\n",
    "                    if username:  # Verificar si se proporciona un nombre de usuario\n",
    "                        # Incrementar el contador para este nombre de usuario\n",
    "                        username_count[username] = username_count.get(username, 0) + 1\n",
    "\n",
    "    # Ordenar el diccionario por la frecuencia de menciones en orden descendente\n",
    "    sorted_username_count = sorted(username_count.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Tomar los top 10 usuarios más mencionados\n",
    "    top_10_users = sorted_username_count[:10]\n",
    "\n",
    "    return top_10_users\n",
    "\n",
    "# Ejecuta la función dentro del perfilador y guarda los resultados\n",
    "profiler = cProfile.Profile()\n",
    "profiler.enable()\n",
    "file_path = \"gs://challenge-de/farmers-protest-tweets-2021-2-4.json\"\n",
    "q3_time(file_path)\n",
    "profiler.disable()\n",
    "\n",
    "# Genera estadísticas a partir del perfil\n",
    "stats = pstats.Stats(profiler)\n",
    "# Imprime el resumen con el número total de llamadas y el tiempo total de ejecución\n",
    "print(stats.total_calls, \"function calls in\", stats.total_tt, \"seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "5053280 function calls in 17.320575784000003 seconds"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-root-py",
   "name": "workbench-notebooks.m118",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m118"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
